{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8132c8e-7489-4ef7-9868-f62cf5219fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 导入必要的库并设置项目路径 ---\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D # For custom legends\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "import torch_geometric.data\n",
    "import umap\n",
    "\n",
    "# 假设本 Notebook 位于项目的 'test/' 目录下\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "print(f\"项目根目录已添加到系统路径: {PROJECT_ROOT}\")\n",
    "\n",
    "from src.models.combined_model import CombinedModel\n",
    "from src.utils import set_seed, get_device\n",
    "from src.data_loader import load_gene_graph_data, create_cells_by_day_mapping\n",
    "from src.evaluate import _get_point_estimate_from_params, _reshape_params_for_loss_or_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc907cdb-05cd-4e47-8f59-4206395c6d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2. 配置\n",
    "# --- 用户可配置参数 ---\n",
    "\n",
    "# 指向您的主配置文件\n",
    "CONFIG_PATH = os.path.join(PROJECT_ROOT, \"configs/main_config.yaml\")\n",
    "\n",
    "# 指向您已经训练好的、想要评估的【联合模型】检查点\n",
    "CHECKPOINT_PATH = os.path.join(PROJECT_ROOT, \"results/experiment_stable_start/checkpoints/joint_train_best.pt\")\n",
    "\n",
    "# 要评估的时间点将从数据中自动获取\n",
    "\n",
    "# --- 可视化参数 ---\n",
    "NUM_SAMPLES_PER_DAY = 200 # 为每个时间点采样的细胞数量\n",
    "UMAP_N_NEIGHBORS = 15\n",
    "UMAP_MIN_DIST = 0.1\n",
    "UMAP_METRIC = 'euclidean'\n",
    "UMAP_RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6d094a-4ec1-4fce-bf23-1ec5d0e6ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3. 加载配置、数据和模型\n",
    "# --- 加载配置 ---\n",
    "if not os.path.exists(CONFIG_PATH):\n",
    "    raise FileNotFoundError(f\"配置文件未找到: {CONFIG_PATH}\")\n",
    "config = OmegaConf.load(CONFIG_PATH)\n",
    "\n",
    "set_seed(config.seed)\n",
    "device = get_device(config.training_params.device)\n",
    "print(f\"正在使用设备: {device}\")\n",
    "\n",
    "# --- 加载数据 ---\n",
    "print(\"正在加载数据...\")\n",
    "actual_data_dir = config.data_params.data_dir\n",
    "if not os.path.isabs(actual_data_dir):\n",
    "    actual_data_dir = os.path.join(PROJECT_ROOT, actual_data_dir)\n",
    "if not os.path.exists(actual_data_dir):\n",
    "    raise FileNotFoundError(f\"数据目录未找到: {actual_data_dir}\")\n",
    "X_all_np, shared_edge_index, shared_edge_weight, gene_names, cell_names, meta_df = \\\n",
    "    load_gene_graph_data(actual_data_dir, config)\n",
    "cells_by_day_indices = create_cells_by_day_mapping(meta_df, cell_names)\n",
    "print(\"数据加载完成。\")\n",
    "\n",
    "# --- 加载模型 ---\n",
    "print(f\"正在从检查点加载模型: {CHECKPOINT_PATH}\")\n",
    "if not os.path.exists(CHECKPOINT_PATH):\n",
    "    raise FileNotFoundError(f\"检查点文件未找到: {CHECKPOINT_PATH}\")\n",
    "# 加载 CombinedModel\n",
    "model = CombinedModel(config)\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "\n",
    "state_dict = checkpoint['model_state_dict']\n",
    "if all(key.startswith('module.') for key in state_dict.keys()):\n",
    "    print(\"检查点来自DDP模型，正在移除 'module.' 前缀。\")\n",
    "    state_dict = {k[7:]: v for k, v in state_dict.items()}\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"模型加载完成。\")\n",
    "\n",
    "# --- 获取模型和数据参数 ---\n",
    "is_variational = bool(config.model_params.encoder.get(\"is_variational\", False))\n",
    "decoder_distribution = config.model_params.decoder.get(\"distribution\", \"gaussian\")\n",
    "num_dist_params = config.model_params.decoder.get(\"num_dist_params\", 2)\n",
    "num_genes = int(config.model_params.num_genes)\n",
    "\n",
    "# 自动确定所有要评估的时间点\n",
    "DAYS_TO_EVALUATE = sorted(cells_by_day_indices.keys())\n",
    "print(f\"将自动评估以下所有时间点: {DAYS_TO_EVALUATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efa2931-747a-4c41-a54f-dce4cd1daa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 4. 生成重构数据 (只通过VGAE部分)\n",
    "# --- 初始化数据收集列表 ---\n",
    "all_expressions_list = []\n",
    "all_latent_list = []\n",
    "all_type_labels_list = [] \n",
    "all_day_labels_list = [] \n",
    "\n",
    "with torch.no_grad():\n",
    "    for day in tqdm(DAYS_TO_EVALUATE, desc=\"处理各个时间点\"):\n",
    "        if day not in cells_by_day_indices or len(cells_by_day_indices[day]) == 0:\n",
    "            print(f\"警告: 时间点 {day} 没有有效细胞，跳过。\")\n",
    "            continue\n",
    "        \n",
    "        day_indices = np.random.choice(cells_by_day_indices[day], min(NUM_SAMPLES_PER_DAY, len(cells_by_day_indices[day])), replace=False)\n",
    "        real_expressions = X_all_np[day_indices]\n",
    "        \n",
    "        day_data_list = [torch_geometric.data.Data(x=torch.tensor(expr, dtype=torch.float32).unsqueeze(-1), edge_index=shared_edge_index) for expr in real_expressions]\n",
    "        day_batch_pyg = torch_geometric.data.Batch.from_data_list(day_data_list).to(device)\n",
    "        \n",
    "        # --- 通过VGAE进行编码和解码 ---\n",
    "        gae_outputs = model.graph_autoencoder(day_batch_pyg) \n",
    "        \n",
    "        # --- 收集潜空间数据 ---\n",
    "        real_mu_nodes = gae_outputs.get(\"mu_nodes\")\n",
    "        real_z_batch = gae_outputs.get(\"z_batch\")\n",
    "        \n",
    "        real_latent_repr = real_mu_nodes if is_variational and real_mu_nodes is not None else gae_outputs.get(\"sampled_z_nodes\")\n",
    "        if real_latent_repr is not None and real_latent_repr.numel() > 0:\n",
    "            all_latent_list.append(global_mean_pool(real_latent_repr, real_z_batch).detach().cpu().numpy())\n",
    "        \n",
    "        # --- 收集表达空间数据 ---\n",
    "        reconstructed_params = gae_outputs.get(\"reconstructed_params\")\n",
    "        reshaped_params = _reshape_params_for_loss_or_eval(reconstructed_params, (len(day_indices), num_genes), num_dist_params)\n",
    "        recon_expressions_est = _get_point_estimate_from_params(reshaped_params, decoder_distribution, device)\n",
    "        recon_expressions_np = recon_expressions_est.detach().cpu().numpy()\n",
    "        all_expressions_list.append(real_expressions)\n",
    "        all_expressions_list.append(recon_expressions_np)\n",
    "\n",
    "        # --- 重新编码重构后的表达，以评估潜空间重构 ---\n",
    "        recon_data_list = [torch_geometric.data.Data(x=torch.tensor(expr, dtype=torch.float32).unsqueeze(-1), edge_index=shared_edge_index) for expr in recon_expressions_np]\n",
    "        recon_batch_pyg = torch_geometric.data.Batch.from_data_list(recon_data_list).to(device)\n",
    "        _, recon_mu_nodes, _, recon_batch, _ = model.graph_autoencoder.encode(recon_batch_pyg, return_pooling_details=False)\n",
    "        \n",
    "        recon_latent_repr = recon_mu_nodes if is_variational and recon_mu_nodes is not None else _\n",
    "        if recon_latent_repr is not None and recon_latent_repr.numel() > 0:\n",
    "            all_latent_list.append(global_mean_pool(recon_latent_repr, recon_batch).detach().cpu().numpy())\n",
    "        \n",
    "        # --- 收集标签 ---\n",
    "        all_day_labels_list.extend([day] * len(real_expressions))\n",
    "        all_day_labels_list.extend([day] * len(recon_expressions_np))\n",
    "        all_type_labels_list.extend([\"Real\"] * len(real_expressions))\n",
    "        all_type_labels_list.extend([\"Recon\"] * len(recon_expressions_np))\n",
    "\n",
    "\n",
    "# --- 合并所有数据 ---\n",
    "if not all_expressions_list:\n",
    "    raise ValueError(\"没有为UMAP收集到任何数据。请检查 DAYS_TO_EVALUATE 是否有效。\")\n",
    "    \n",
    "combined_expressions_np = np.concatenate(all_expressions_list, axis=0)\n",
    "combined_latent_np = np.concatenate(all_latent_list, axis=0)\n",
    "day_labels_np = np.array(all_day_labels_list)\n",
    "type_labels_np = np.array(all_type_labels_list)\n",
    "\n",
    "print(f\"为UMAP准备的总数据点数量: {combined_expressions_np.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e76105-f873-4fad-90fa-cd04c1e2a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 5. UMAP降维与可视化\n",
    "def plot_space(embedding, day_labels, type_labels, title, output_filename):\n",
    "    fig, ax = plt.subplots(figsize=(16, 12))\n",
    "    unique_days = np.unique(day_labels)\n",
    "    colors = plt.get_cmap('viridis', len(unique_days))\n",
    "    day_to_color = {day: colors(i) for i, day in enumerate(unique_days)}\n",
    "\n",
    "    for day in unique_days:\n",
    "        real_idx = (day_labels == day) & (type_labels == \"Real\")\n",
    "        recon_idx = (day_labels == day) & (type_labels == \"Recon\")\n",
    "        color = day_to_color[day]\n",
    "        \n",
    "        ax.scatter(embedding[real_idx, 0], embedding[real_idx, 1], color=color, marker='o', s=30, alpha=0.1)\n",
    "        ax.scatter(embedding[recon_idx, 0], embedding[recon_idx, 1], color=color, marker='x', s=40, alpha=1)\n",
    "\n",
    "    day_legend_elements = [Line2D([0], [0], color=day_to_color[day], lw=4, label=f'Day {day:.2f}') for day in unique_days]\n",
    "    marker_legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='gray', label='Real Data', linestyle='None', markersize=10, alpha=0.1),\n",
    "        Line2D([0], [0], marker='x', color='gray', label='Reconstructed Data', linestyle='None', markersize=10, alpha=1)\n",
    "    ]\n",
    "    ax.legend(handles=day_legend_elements + marker_legend_elements, loc='best', bbox_to_anchor=(1.2, 1), fontsize=10)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel('UMAP 1', fontsize=14)\n",
    "    ax.set_ylabel('UMAP 2', fontsize=14)\n",
    "    ax.grid(True, linestyle='--', alpha=0.6)\n",
    "    fig.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "\n",
    "    output_dir_eval = config.evaluation_params.get(\"output_dir\", \"results/eval_output\")\n",
    "    os.makedirs(output_dir_eval, exist_ok=True)\n",
    "    plot_path = os.path.join(output_dir_eval, output_filename)\n",
    "    plt.savefig(plot_path, dpi=300)\n",
    "    print(f\"UMAP图已保存到: {plot_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# --- 表达空间 ---\n",
    "print(\"\\n正在处理表达空间UMAP...\")\n",
    "embedding_expr = umap.UMAP(n_neighbors=UMAP_N_NEIGHBORS, min_dist=UMAP_MIN_DIST, metric=UMAP_METRIC, random_state=UMAP_RANDOM_STATE).fit_transform(combined_expressions_np)\n",
    "plot_space(embedding_expr, day_labels_np, type_labels_np, \n",
    "           'UMAP of Real vs. Reconstructed Gene Expression by Day',\n",
    "           \"umap_vgae_reconstruction_expression_space.png\")\n",
    "\n",
    "# --- 潜空间 ---\n",
    "print(\"\\n正在处理潜空间UMAP...\")\n",
    "embedding_latent = umap.UMAP(n_neighbors=UMAP_N_NEIGHBORS, min_dist=UMAP_MIN_DIST, metric='cosine', random_state=UMAP_RANDOM_STATE).fit_transform(combined_latent_np)\n",
    "plot_space(embedding_latent, day_labels_np, type_labels_np,\n",
    "           'UMAP of Real vs. Reconstructed Latent Representations by Day',\n",
    "           \"umap_vgae_reconstruction_latent_space.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
